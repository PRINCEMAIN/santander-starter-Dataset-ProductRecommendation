{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Santander wants to find which customers will make a specific transaction in the future, irrespective of the amount of money transacted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pickle\n",
    "s3_resource = boto3.resource('s3')\n",
    "filename = 'ProdRecommed.npy'\n",
    "dicttprodrec = s3_resource.Object('santander-starter-train','dictionaries/ProdRecommed.npy').download_file(filename)\n",
    "ProdRecommed_dict= np.load(\"ProdRecommed.npy\",allow_pickle='TRUE').item()\n",
    "#ProdRecommed_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pickle\n",
    "s3_resource = boto3.resource('s3')\n",
    "filename = 'Channel.npy'\n",
    "dictchannel = s3_resource.Object('santander-starter-train','dictionaries/Channel.npy').download_file(filename)\n",
    "Channel_dict= np.load(\"Channel.npy\",allow_pickle='TRUE').item()\n",
    "#Channel_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Residence_Code.npy'\n",
    "dicttprodrec = s3_resource.Object('santander-starter-train','dictionaries/Residence_Code.npy').download_file(filename)\n",
    "Residence_Code= np.load('Residence_Code.npy',allow_pickle='TRUE').item()\n",
    "#Residence_Code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Importing all models\n",
    "\n",
    "# Classification\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, \\\n",
    "    RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, \\\n",
    "    RandomForestRegressor, VotingRegressor\n",
    "\n",
    "\n",
    "#import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "#import catboost as cat\n",
    "#from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "#print(os.listdir(\"../input\"))\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and Reducing Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 170.22 MB\n",
      "Memory usage after optimization is: 58.01 MB\n",
      "Decreased by 65.9%\n"
     ]
    }
   ],
   "source": [
    "#train = import_data(\"train_ver2.csv\")\n",
    "test = import_data(\"s3://santander-starter-train/testingdatasets/test_ver2.csv\")\n",
    "#sub = import_data(\"sample_submission.csv\")\n",
    "\n",
    "#print(\"\\n\\nTrain Size : \\t{}\\nTest Size : \\t{}\".format(train.shape, test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintesting = pd.DataFrame(test.values,columns=['date', 'customer_code', 'emp_status', 'residence_code', 'sex', 'age', 'date_first_prod', 'new_customer', 'seniority_inmonths',\n",
    "'prime_customer', 'prime_lastdate', 'customer_type', 'customer_relation', 'is_residence', 'is_foreigner', 'spouse', 'channel',\n",
    "'deceased', 'primary_address', 'province_code', 'province_name', 'status_ai', 'gincome', 'social_segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintesting.drop(columns=['province_name'],axis=1,inplace=True) #Province Code shall be used instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                       0\n",
       "customer_code              0\n",
       "emp_status                 0\n",
       "residence_code             0\n",
       "sex                        5\n",
       "age                        0\n",
       "date_first_prod            0\n",
       "new_customer               0\n",
       "seniority_inmonths         0\n",
       "prime_customer             0\n",
       "prime_lastdate        927932\n",
       "customer_type             23\n",
       "customer_relation         23\n",
       "is_residence               0\n",
       "is_foreigner               0\n",
       "spouse                929511\n",
       "channel                 2081\n",
       "deceased                   0\n",
       "primary_address            0\n",
       "province_code           3996\n",
       "status_ai                  0\n",
       "gincome                    0\n",
       "social_segment          2248\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## verify which all columns have Null / NaN values\n",
    "traintesting.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintesting['date'] = traintesting['date'].replace('-','',regex=True).str.strip(' ,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintesting['date_first_prod'] = traintesting['date_first_prod'].replace('-','',regex=True).str.strip(' ,')\n",
    "traintesting['prime_lastdate'] = traintesting['prime_lastdate'].replace('-','',regex=True).str.strip(' ,')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         19950116\n",
       "1         20130828\n",
       "2         20130828\n",
       "3         20130828\n",
       "4         20130828\n",
       "            ...   \n",
       "929610    19990421\n",
       "929611    20061129\n",
       "929612    20061129\n",
       "929613    20061129\n",
       "929614    20061129\n",
       "Name: date_first_prod, Length: 929615, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintesting['date_first_prod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Dictionaries\n",
    "#Channel_dict = np.load('Channel.npy',allow_pickle='TRUE').item()\n",
    "#Residence_Code= np.load('Residence_Code.npy',allow_pickle='TRUE').item()\n",
    "#ProdRecommed_dict= np.load('ProdRecommed.npy',allow_pickle='TRUE').item()\n",
    "#Residence_Code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "929610    0\n",
       "929611    0\n",
       "929612    0\n",
       "929613    0\n",
       "929614    0\n",
       "Name: residence_code, Length: 929615, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Create a new dictionary for ProductRecommendation Column and map it: Prince G\n",
    "#daf1 = pd.DataFrame(traintesting['residence_code'].unique())\n",
    "#di1= daf1.to_dict()\n",
    "#di1[0].items()\n",
    "new_dict_res_code = dict([(value, key) for key, value in Residence_Code[0].items()]) \n",
    "#new_dict_res_code\n",
    "traintesting['residence_code'] = traintesting['residence_code'].map(new_dict_res_code)\n",
    "traintesting['residence_code']\n",
    "#new_dict_res_code\n",
    "#traintesting['residence_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          5\n",
       "1          5\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "          ..\n",
       "929610     5\n",
       "929611     4\n",
       "929612    67\n",
       "929613     4\n",
       "929614     5\n",
       "Name: channel, Length: 929615, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Create a new dictionary for ProductRecommendation Column and map it: Prince G\n",
    "#daf2 = pd.DataFrame(traintesting['channel'].unique())\n",
    "#di2= daf2.to_dict()\n",
    "#di1[0].items()\n",
    "new_dict_channel_code = dict([(value, key) for key, value in Channel_dict[0].items()]) \n",
    "#new_dict_res_code\n",
    "traintesting['channel'] = traintesting['channel'].map(new_dict_channel_code)\n",
    "traintesting['channel']\n",
    "#new_dict_res_code\n",
    "#traintesting['residence_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Mapping the columns to be used for algorithm to process\n",
    "traintesting['customer_type'] = traintesting['customer_type'].map({'1.0':1, '1':1, '2.0':2, '2':2, '3.0':3, '3':3, '4.0':4, '4':4, 'P':'5'})\n",
    "traintesting['emp_status'] = traintesting['emp_status'].map({'N':1, 'A':2, 'B':3, 'F':4, 'S':5})\n",
    "traintesting['sex'] = traintesting['sex'].map({'V':'1', 'H':'2'})\n",
    "traintesting['deceased'] = traintesting['deceased'].map({'N':'0', 'S':'1'})\n",
    "traintesting['is_foreigner'] = traintesting['is_foreigner'].map({'N':'1', 'S':'2'})\n",
    "traintesting['is_residence'] = traintesting['is_residence'].map({'N':'1', 'S':'2'})\n",
    "traintesting['spouse'] = traintesting['spouse'].map({'N':'1', 'S':'2'})\n",
    "traintesting['social_segment'] = traintesting['social_segment'].map({'01 - TOP':'1', '02 - PARTICULARE':'2', '03 - UNIVERSITARIO':'3'})\n",
    "traintesting['customer_relation'] = traintesting['social_segment'].map({'A':'1', 'I':'2', 'P':'3', 'R':'4', 'N':'5'})\n",
    "#traintesting.replace(' NA',\"0\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintesting.replace(' NA',\"NaN\",inplace=True)\n",
    "traintesting.replace('     NA',\"NaN\",inplace=True)\n",
    "#traintesting.replace('',\"0\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traintesting.dropna(axis=1)\n",
    "traintesting['spouse'].replace('NaN','2',inplace=True)\n",
    "traintesting['spouse'].unique()\n",
    "traintesting['spouse'].fillna('2',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintesting['social_segment'].fillna('3',inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#traintesting['age'].fillna(traintesting['age'].mean(),inplace=True)#Gross Income is considered for Mean of Age\n",
    "traintesting['emp_status'].fillna('1',inplace=True)\n",
    "traintesting['residence_code'].fillna('1',inplace=True)\n",
    "traintesting['deceased'].fillna('0',inplace=True)\n",
    "traintesting['new_customer'].fillna('0.0',inplace=True)\n",
    "traintesting['status_ai'].fillna('0.0',inplace=True)\n",
    "traintesting['channel'].fillna('1',inplace=True)\n",
    "traintesting['prime_customer'].fillna('1.0',inplace=True)\n",
    "traintesting['customer_type'].fillna('1',inplace=True)\n",
    "traintesting['sex'].fillna('1',inplace=True)\n",
    "traintesting['is_residence'].fillna('1',inplace=True) #Replace NaN with value 1 means he is not a resident\n",
    "traintesting['is_foreigner'].fillna('1',inplace=True) #Replace NaN with value 1 means he is not a foreigner\n",
    "traintesting['customer_relation'].fillna('0',inplace=True)\n",
    "traintesting['primary_address'].fillna('0',inplace=True)#Replace NaN with 0 as customer has not given Primary address\n",
    "traintesting['province_code'].fillna('0.0',inplace=True)#Replace NaN with 0.0 , the value not existing in Province Code list\n",
    "#traintesting['province_name'].fillna('NotPROVIDED',inplace=True)#Replace NaN with NotPROVIDED , the value not existing in Province Name list\n",
    "traintesting['date_first_prod'].fillna('0',inplace=True)#Replace NaN with 0 , to identfy that date not existing, in such cases the product offering may differ\n",
    "traintesting['prime_lastdate'].fillna('0',inplace=True)#Replace NaN with 0 , to identfy that date not existing, in such cases the product offering may differ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           326124.90\n",
       "1              134254\n",
       "2              134254\n",
       "3           148402.98\n",
       "4           106885.80\n",
       "             ...     \n",
       "929610      128643.57\n",
       "929611         134254\n",
       "929612       72765.27\n",
       "929613      147488.88\n",
       "929614         134254\n",
       "Name: gincome, Length: 929615, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#traintesting['gincome'].fillna(traintesting['gincome'].mean(),inplace=True)#Gross Income is considered for Mean of incomes. This may be wrong assumption\n",
    "#traintesting['gincome'].astype('float64')\n",
    "traintesting['gincome'].replace('         NA','134254',inplace=True)\n",
    "traintesting['gincome'].fillna('134254.3',inplace=True)\n",
    "traintesting['gincome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24     50706\n",
       "23     49604\n",
       "22     47674\n",
       "21     46322\n",
       "25     41429\n",
       "       ...  \n",
       "114        6\n",
       "127        1\n",
       "117        1\n",
       "118        1\n",
       "164        1\n",
       "Name: age, Length: 118, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintesting['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintesting['age'].fillna('25',inplace=True)#May be a wromg assumption from Business prespective\n",
    "traintesting['age'].replace('NaN','25',inplace=True)#May be a wromg assumption from Business prespective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    256,      34,      11,       5,      33,       4,      30,\n",
       "            32,      15,      18,      25,      23,      16,      26,\n",
       "            31,      13,      27,      29,      20,       8,       7,\n",
       "            24,      14,       3,       1,      10,      28,      22,\n",
       "            21,       2,      19,      17,      12,       9,       6,\n",
       "            37,      35,      36,      38,     150,      41,      40,\n",
       "            39,       0,      47,      48,      45,      42,      44,\n",
       "            46,      49,      43,      51,      50,      52,      55,\n",
       "            54,      53,      56,     186,     168,     128,     120,\n",
       "           220,      75,     172,     103,     159,     145,     135,\n",
       "           160,      93,     156,     157,     170,     148,     175,\n",
       "           176,     167,     104,     123,     133,     147,     112,\n",
       "            87,      99,     129,     171,     134,     144,     169,\n",
       "            72,     149,     106,     166,     113,     184,     139,\n",
       "           187,      62,     152,      81,     196,      78,     146,\n",
       "           161,     174,      96,      70,     109,     155,     131,\n",
       "           163,     143,      89,     158,     153,      73,      59,\n",
       "            65,     177,      95,     124,     132,      68,     138,\n",
       "           130,      98,      84,     122,      74,     141,     100,\n",
       "           115,     164,     204,      64,     136,     119,      88,\n",
       "           121,     117,     118,     127,     125,     165,      67,\n",
       "            97,      58,     111,     173,      77,     162,      63,\n",
       "           202,      94,     137,     110,     194,     154,     102,\n",
       "           199,     116,     140,     114,     105,     244,     195,\n",
       "           151,      86,      69,      76,     126,      90,     107,\n",
       "           142,      82,     108,      92,      79,      91,     233,\n",
       "           101,      83,     215,     217,     248,      80,     207,\n",
       "           188,      60,      66,     179,     185,     224,      57,\n",
       "           190,      61,     180,     206,     212,     197,      71,\n",
       "           246,     221,     183,     210,     219,     198,      85,\n",
       "           229,     231,     181,     213,     200,     228,     237,\n",
       "           192,     205,     230,     178,     209,     191,     189,\n",
       "           182,     218,     203,     236,     227,     201,     243,\n",
       "           216,     211,     241,     226,     193,     242,     214,\n",
       "           223,     235,     240,     238,     225,     234,     253,\n",
       "           252,     208,     222,     232,     249,     239,     247,\n",
       "           257,     251,     245,     254,     255,     250, -999999])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintesting['seniority_inmonths'].fillna('100',inplace=True)#May be a wromg assumption from Business prespective\n",
    "traintesting['seniority_inmonths'].replace('NaN','100',inplace=True)#May be a wromg assumption from Business prespective\n",
    "traintesting['seniority_inmonths'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintesting['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56,  36,  22,  51,  41,  33,  23,  43,  63,  62,  32,  58,  71,\n",
       "        31,  30,  59,  45,  37,  39,  38,  46,  34,  35,  42,  29,  88,\n",
       "        64,  48,  72,  47,  27,  24,  50,  49,  57,  67,  25,  28,  13,\n",
       "        40,  53,  54,  26,  11,  21,  60,  44,  55,   7,  52,  66,  90,\n",
       "        73,  78,  79,  61,  69,  12,   9,  65,  77,  83,  81,  10,   5,\n",
       "        18,  17,  87,  70,  80,  75,  68,  74,  16,   4,  82,  91,  76,\n",
       "        19,  15,   6,  97,  89,  85,  86,  14,  20,   8,  84,  95,  93,\n",
       "       100,  96,  92,  98,  94, 105, 102, 101, 104, 103,  99,   3,   2,\n",
       "       116, 106, 107, 109, 110, 117, 108, 113, 111, 112, 114, 164, 118,\n",
       "       127])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintesting['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    893654\n",
       "1     35961\n",
       "Name: social_segment, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintesting['social_segment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134254         227965\n",
       "  451931.22       354\n",
       "  463625.16       111\n",
       "  128318.52        91\n",
       "  181042.20        91\n",
       "                ...  \n",
       "  253983.03         1\n",
       "   65224.68         1\n",
       "   68072.52         1\n",
       "  131335.38         1\n",
       "   76026.81         1\n",
       "Name: gincome, Length: 516403, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintesting['gincome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([326124.9 , 134254.  , 148402.98, ..., 139164.12, 100647.45,\n",
       "        72765.27])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintesting['gincome'] = traintesting['gincome'].astype(np.float64)\n",
    "traintesting['gincome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                  0\n",
       "customer_code         0\n",
       "emp_status            0\n",
       "residence_code        0\n",
       "sex                   0\n",
       "age                   0\n",
       "date_first_prod       0\n",
       "new_customer          0\n",
       "seniority_inmonths    0\n",
       "prime_customer        0\n",
       "prime_lastdate        0\n",
       "customer_type         0\n",
       "customer_relation     0\n",
       "is_residence          0\n",
       "is_foreigner          0\n",
       "spouse                0\n",
       "channel               0\n",
       "deceased              0\n",
       "primary_address       0\n",
       "province_code         0\n",
       "status_ai             0\n",
       "gincome               0\n",
       "social_segment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## verify which all columns have Null / NaN values\n",
    "traintesting.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traintesting = traintesting.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintesting.to_csv(r's3://santander-starter-train/PreProcessedtrainingdata/testingdatapreprocessed/Data_testing_PreProcessed.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessed data is loaded sucessfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
